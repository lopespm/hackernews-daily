<!doctype html>

<html lang="en">
<head>
	<title>Hacker News Daily</title>
	<meta name="description" content="Lightweight daily best Hacker News posts, with screenshots and top comments. No JavaScript used.">
	<meta name="author" content="Pedro Lopes">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta charset="utf-8">
	<link rel="stylesheet" href="css/styles.css?v=1.0">
	<link href="/favicon.png" rel="icon">
</head>

<body>

<div class="container">

	<div class="navbar">
		<div class="navbar__timespan">
			
				<span class="navbar__timespan_item-current navbar__timespan_item-spacing">Latest</span>
			
			
				<a href='all_without_images.html'>All</a>
			
		</div>
		<div class="navbar__no-images">
			
				<a href='index.html'
				>Enable Previews</a>
			
		</div>
	</div>

	
	<div class="day__date">09 August 2022</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://metaphysic.ai/to-uncover-a-deepfake-video-call-ask-the-caller-to-turn-sideways/">To uncover a deepfake video call, ask the caller to turn sideways</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32384653">
						
							
								<p class="story__comment_first line-clamp">"Source: I work in the field.This is a current limitation, and an artifact of the data+method but not something that should be relied upon.If we do some adversary modelling, we can find two ways to work around this:1) actively generate and search for such data; perhaps expensive for small actors but not well equipped malicious ones.2) wait for deep learning to catch up, e.g. by extending NERFs (neural radiance fields) to faces; matter of time.Now, if your company/government is on the bleeding edge of ML-based deception, they can have such policy, and they will update it 12-18-24 months (or whenever (1) or (2) materialises). However, I don&#39;t know one organisation that doesn&#39;t have some outdated security guideline that they cling to, e.g. old school password rules and rotations.Will &#34;turning sideways to spot a deepfake&#34; be a valid test in 5 years? Prolly no, so don&#39;t base your secops around this."</p>
							
						
							
								<p class="story__comment_others">"It&#39;s a constant cat-and-mouse game. When I worked in this space (2019-2021), the best defense against deep fakes was looking at the microfacial behavior/kinematics of the &#34;puppetmaster&#34; and comparing against known standards of the deepfake subject. Works even if the fake is pixel-perfect (since it looks at the facial &#34;wireframe&#34; rather than the image itself). The obvious downside is you need sample data of the subject (and usually tons of it). I wonder if that general approach can be optimized. E.g. Deep fakes tend to struggle with certain fine movement/detail, if you had a reflection of the subject, the algorithm would have to not just replicate the main face and the mirror, but also be completely optically consistent.Was a fun project, but the cat-and-mouse feeling was inescapable. 
For those curious, look up the DARPA MediFor project. Siwei Lyu (in the article) did a bunch of work in this space. Also see Hany Farid and Shruti Agarwal. They&#39;ve worked specifically with deep fake detection.https://arxiv.org/abs/2004.14491"</p>
							
						
							
								<p class="story__comment_others">"Slightly more robust method...Ask the caller to move out of the frame and then back in again.You will see a noticable &#39;step&#39; as the face that is partially in the frame suddenly gets detected as a face and the deepfake is applied.The only way around this is to crop the input video quite heavily - by at least one face diameter, which is a lot if the user is near the camera."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://jakobgreenfeld.com/insight-porn">No More “Insight Porn”</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32384613">
						
							
								<p class="story__comment_first line-clamp">"I got super lucky. I started a company and didn’t really have any meaningful traction. I was about to shut it down. Walking out of the grocery store one night after work, I passed by my former manager when I was an intern. We got to talk for about 30 seconds, mentioned my company, she asked me to email her. I did, and that very quickly led to my first big customer which makes me about double what a FAANG swe would make.My advice: get lucky.My insight porn version: 10 easy steps I used to get $500K ARR and how you can do it too"</p>
							
						
							
								<p class="story__comment_others">"Jonathan Haidt speaks about something similar in The Happiness Hypothesis. Epiphanies can only take you so far, before their novelty wears off and they lose the power to change your behaviour. This is why self-help book readers tend to keep reading self-help books. 4 weeks after finishing one they need another hit of epiphanies.Even the lamest examples listed in the OP article can probably give someone a boost in productivity for a while, as long as that epiphanic rush lasts.I&#39;ve felt this in myself over the years. I&#39;d hit a low point and try to hoist myself out of it, with some sombre new ethical code for creating a work ethic; some new note taking system; or epiphany gleaned from Shakespeare or Nietzsche.You can see it in the Jordan Peterson clips that haunt my YouTube shorts."</p>
							
						
							
								<p class="story__comment_others">"Out of the 3 &#34;Insight Porn&#34; examples linked in the article, I think the Paul Graham essay seems out of place. I know I know, this is hacker news. Yet another person sticking up for pg. But I just don&#39;t think this essay (or others) is really trying to boil some dream/goal into steps. In fact, in the &#34;How to get startup ideas&#34; referenced in this post, pg says:&#34;So if you can&#39;t predict whether there&#39;s a path out of an idea, how do you choose between ideas? The truth is disappointing but interesting: if you&#39;re the right sort of person, you have the right sort of hunches. If you&#39;re at the leading edge of a field that&#39;s changing fast, when you have a hunch that something is worth doing, you&#39;re more likely to be right.&#34;To me, he is doing the opposite of insight porn. Basically saying this might not even be for you. He doesn&#39;t even suggest that you go become an expert in something. Rather, he just throws his hands up. He tries to spare you from the disappointment of hearing this by calling it &#34;interesting&#34;. That contrasts _a lot_ with what most of the insight porn is trying to convince you of. They rarely try to disappoint you and mostly just hype/pump you up."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://deephaven.io/blog/2022/08/08/AI-generated-blog-thumbnails/">I replaced all our blog thumbnails using DALL·E 2</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32390526">
						
							
								<p class="story__comment_first line-clamp">"&gt;&#34;While the role of the artist isn’t going away soon, the role of stock image sites might disappear. &#34;Not, yet. While it&#39;s cheap relative to stock images, it&#39;s time consuming to generate exactly what you want. Prices for stock images will collapse for the common quick to use images but the price for the specialized high end images will hold their value or even increase in value. Those historical and such images will continue to be valuable.It will be interesting to see if a specialized job will rise where people will get paid to generate just the right image. It might be called &#34;A.I. image artist &#34; This individual will generate an image with an A.I. but use graphic tools to finalize it for use."</p>
							
						
							
								<p class="story__comment_others">"Honestly, this is an awesome use of DALL-E and I&#39;ll probably start doing the same for my blogIt&#39;s perfect because:- The images just need to get across a vibe, they don&#39;t need to be perfect- It&#39;s a low-value enough use of images that you&#39;d probably never commission a human artist to do them; instead you&#39;d either use stock photos, or skip having images completely- The nature of header images for a tech blog tends toward the abstract/surreal, which means it&#39;s either hard to find the right stock images, or the ones you do find will be super abstract to the point of being boringAll of these make it a great use of the technology"</p>
							
						
							
								<p class="story__comment_others">"Am I one of the few people who finds these generated pictures really bad?  They often have weird and unsettling details when you look closely.I mean, it’s an incredible achievement in AI that we can generate images at this level, but I don’t want them shown to me on a daily basis while I’m reading blogs."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://oceanexplorer.noaa.gov/news/oer-updates/2022/mysterious-holes-seafloor/mysterious-holes-seafloor.html">Mysterious holes on the seafloor</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32379066">
						
							
								<p class="story__comment_first line-clamp">"This reminds me of another deep sea mystery trace, Paleodictyon[1]. Once an unconnected set of geometric fossils and modern hole patterns, it&#39;s been discovered that this phenomenon has occurred in a consistent form for half a billion years up to the present day.[1] https://en.wikipedia.org/wiki/Paleodictyon"</p>
							
						
							
								<p class="story__comment_others">"Some theories- A large starfish rolls along the sea floor, leaving the dashed line- A crab bouncing on its back, ricocheting with a current- A fish with an IQ of 300 hoping that alien intelligence from above will locate it, left a mark in the mud, to liberate it- The world was manufactured in a sowing factory.- The world sustained an injury and had stiches"</p>
							
						
							
								<p class="story__comment_others">"Given the irregular distance between holes and the different angles of the holes, I&#39;d guess something organic. There&#39;s still a lot we don&#39;t know about even well known fish like sharks, what to talk of fish or marine life that we have yet to discover. Seeing the raised ridge along the entire set of holes makes me wonder if they&#39;re from some kind of eggs that hatched after being embedded in the seabed.It&#39;s amazing that there are still so many mysteries like this on Earth."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://github.com/openairplay/airplay2-receiver">Open AirPlay 2 Receiver</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32383820">
						
							
								<p class="story__comment_first line-clamp">"It&#39;s worth stating that the actual crypto code itself is &#34;moderately insane&#34; – https://github.com/openairplay/airplay2-receiver/blob/master... contains the warning:    &#34;&#34;&#34;
    GPLv2
    Python implementation by systemcrash 2022
    Original C implementation of OmgHax by (credit to original author and Foxsen)
    If you want this to work, don&#39;t touch anything. It&#39;s a steaming hot
    rats nest of crypto mess which works. It&#39;s quite performant.
    Resist the urge to refactor. :)
    Avoid +=, -=, ^= etc operators in Garble: they don&#39;t account for overflow.
    &#34;&#34;&#34;

before going into lovely detail, containing lines (e.g. in a method appropriately called Garble) such as    buffer1[15] = ((3 * (((buffer1[72] &gt;&gt; (buffer4[buffer1[190] % 21] &amp; 7)) ^ (buffer1[72] &lt;&lt; ((7 - (buffer4[buffer1[190] % 21] - 1) &amp; 7)))) - (3 * buffer4[buffer1[126] % 21]))) ^ buffer1[15]) &amp; 0xff
        print(f&#39;buffer1[15]:{hex(buffer1[15])}&#39;)

Really, really hats off to whoever worked this out. I have no idea where you&#39;d start."</p>
							
						
							
								<p class="story__comment_others">"What I really want is for someone to crack the Sonos S1 protocol — the one that allows for low-latency P2P sharing - and then to use one of these Airplay 2 bridges with it. Right now the best I can do is to pipe an icecast stream to one which adds seconds of latency. That would allow my older S1 Sonos gear (which I spent thousands on) to have basically unlimited life."</p>
							
						
							
								<p class="story__comment_others">"Great to see some movement on that front.shairport-sync had it long brewing, I think it&#39;s currently still in a dev branch but does work to some extent.https://github.com/mikebrady/shairport-sync/issues/535#issue...EDIT: details here https://github.com/mikebrady/shairport-sync/blob/development..."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://artemis.sh/2022/08/07/emulating-calculators-fast-in-js.html">I 10x&#39;d a TI-84 emulator&#39;s speed by replacing a switch-case</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32381550">
						
							
								<p class="story__comment_first line-clamp">"This is one of those gotcha that trap senior devs way more than junior devs. Growing up with C being my first language, I intuitively associate switch with a jmp table (ie extremely fast). Even though I knew it’s unlikely to be as performant in JS, it never occurred to me that it would actually be slow, until I did a deep dive into low level JS optimization.Related: Matt Godbolt’s talk on emulating 6502 in JS. He also mentions the poor performance of switch for opcodes: https://youtu.be/7WuRq-Wmw5o"</p>
							
						
							
								<p class="story__comment_others">"I like function tables. I think they are cleaner than switch statementsBut, (maybe this is an invalid test), checking today my results suggest a switch is faster than a function table in 2022? At least at a base level. Maybe the more complicated the code for each case gets the less likely it is to get optimized.... which is true in general? large code blocks are less likely to get optimized and a switch is considered one large code block.https://jsbenchit.org/?src=5c1e5bcf62448b6d1750b12893b0f0a1"</p>
							
						
							
								<p class="story__comment_others">"From the title, I expected to find one of the frequently called case statements was unoptimized and they fixed it. Instead, the fix was rewriting all case statements in a way the javascript engine would optimize. Very frustrating if you&#39;re unaware of the obscure rules around it."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://carlmastrangelo.com/blog/why-does-grpc-insist-on-trailers">Why does gRPC insist on trailers?</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32380769">
						
							
								<p class="story__comment_first line-clamp">"&gt; Whether it’s because I was wrong, or failed to make the argument [for HTTP trailers support], I strongly suspect organizational boundaries had a substantial effect. The Area Tech Leads of Cloud also failed to convince their peers in Chrome, and as a result, trailers were ripped out [from the WHATWG fetch specification].FWIW, I personally think it&#39;s a good thing that other teams within Google don&#39;t have too much of an &#34;advantage&#34; for getting features into Chrome, compared to other web developers, however, I also think it&#39;s very unfortunate that a single Chrome engineer gets to decide not only that it shouldn&#39;t be implemented in Chromium, but that that also has the effect of it being removed from the specification. (The linked issue [1] was also opened by a Google employee.)Of course, you might reasonably argue that, without consensus among the browsers to implement a feature, having it in the spec is useless. But nevertheless, with Chromium being an open source project, I think it would be better if it had a more democratic process of deciding which features should be supported (without, of course, requiring Google specifically to implement them, but also without, ideally, giving Google the power to veto them).[1]: https://github.com/whatwg/fetch/issues/772"</p>
							
						
							
								<p class="story__comment_others">"I had never heard of HTTP trailers. So FYI&gt; The Trailer response header allows the sender to include additional fields at the end of chunked messages in order to supply metadata that might be dynamically generated while the message body is sent, such as a message integrity check, digital signature, or post-processing status.https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Tr..."</p>
							
						
							
								<p class="story__comment_others">"A few years ago I worked on a service that had to stream data out using protobuf messages, in a single request that could potentially transfer several gigabytes of data. At the HTTP level it was chunked, but above that I used a protobuf message that contained data plus a checksum of that data, with the last message of the stream containing no data but a checksum of the entire dataset (a flag was included to differentiate between the message types).This simple design led us to find several bugs in clients of this API (e.g. messages dropped or processed twice), and gave us a way to avoid some of the issues mentioned in this article. Even if you don&#39;t use HTTP trailers, you can still use them one layer above and benefit from similar guarantees."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://www.nature.com/articles/s41586-022-05028-x">A physical wiring diagram for the human immune system</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32381790">
						
							
								<p class="story__comment_first line-clamp">"This is kind of stunning.  They appear to have discovered something like 30 novel (previously unknown) immune cell receptor interactions (Fig 1).  Then they built a quantitive model, looked into where these interactions are localized in the body, and lots more beside.  A truly ridiculous amount of information for a single paper. This seems to be the &#39;what&#39;s it all about&#39; paragraph in the paper:&gt; &#34;The immune system is distinctive for being a distributed system. It is not fixed to a single localized organ in the body, but rather is made up of numerous specialized cell types that must adaptably organize their intercellular connections to respond to pathogens and other threats wherever they may appear. We provide a systematic and quantitative view of the cell-surface proteins that enable immune cells to dynamically wire their interactions. The receptor interactions that we report in our network each merit further individualized study to characterize their full roles in health and disease.&#34;For those interested in computational modeling (basically they simulate immune cells circulating freely within the body and interacting based on their receptor types), here&#39;s the supplementary description link (pdf), which is enough for a whole paper on its own.https://static-content.springer.com/esm/art%3A10.1038%2Fs415..."</p>
							
						
							
								<p class="story__comment_others">"As someone who struggles with some vague immune system issues with more questions than answers, I was shocked at how much knowledge of the immune system is presented here. I was immediately curious about how I can apply this knowledge to help me understand my own immune issues. Unfortunately, I don&#39;t know enough about biology and chemistry to understand much of this. But I found this bit near the end encouraging, and a helpful summary of what is presented here:&gt; More broadly, the integrated approaches that we pioneered here for disentangling the immune system provide a framework for future systematic investigations ... Our analysis and the methods that we developed provide a template for future studies looking at physical cell wiring networks in detail. From these combined approaches, we may finally begin to disentangle cellular circuits in immunity and beyond, bridging from individual protein molecules to multicellular behaviour.This seems to be a comprehensive model on a level that has never been seen before, so in that sense, I&#39;m very excited about it. I just hope it doesn&#39;t take decades to trickle down into providers&#39; hands who can actually do something to help patients."</p>
							
						
							
								<p class="story__comment_others">"I am really, really excited for the day we are able to augment or manipulate the immune system in a large and meaningful way.For anyone who likes to visualize the whole kit and kaboodle of current human knowledge check out the virtual metabolic human database. They display an updated map on human metabolismRecon human metabolism map https://www.vmh.life/#reconmap2Paper overview of vmh https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6323901/API Root of vmh https://www.vmh.life/_apiand obviously https://www.ebi.ac.uk/biomodels/ is pretty good toohuman protein atlas https://www.proteinatlas.org/humanproteome/metabolic"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://www.washingtonpost.com/technology/2022/08/02/why-gadgets-die/">Electronics are built with death dates. Let’s not keep them a secret</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32372625">
						
							
								<p class="story__comment_first line-clamp">"It&#39;s not even just batteries. Every laptop I&#39;ve ever owned comes with a AC to DC converter. Every laptop I&#39;ve ever owned has outlived that AC-to-DC converter. Every converter that has failed has failed in exactly the same way: the plug/cord connection at the laptop end becomes unreliable.And every single one of them, across a range of manufacturers, has had the cord not be detachable from the brick. So what could have been a simple $5 replacement cord is now &#34;replace the entire converter&#34; and is now $30 if you try to find a third-party and pray they&#39;re not a fraud, or $50 from the manufacturer. Meanwhile at perfectly good converter (sans cord) is landfill.But lo and behold: the brick-to-wall cord is detachable. And funny that, that one never breaks…"</p>
							
						
							
								<p class="story__comment_others">"It would be great if consumer electronics products had expected lifetime ratings on the front. People would naturally take issue with products with significantly below median lifetime, and also if their own products didn&#39;t live up to the lifetime.It would also make sense to phrase other quantities on product packaging in the way they&#39;re experienced by the consumer: instead of emphasising the wattage of a bulb, if you showed the lumens/$, more efficient bulbs would naturally win out. Instead, LED bulbs have fake wattage numbers to show the equivalent wattage incandescent lighting that would be needed to match the LED."</p>
							
						
							
								<p class="story__comment_others">"I have been a long time enthusiast of high power flashlights. We typically use 18350, 18650, 21700, or 26650. But I have been in dismay as even in this community, companies are starting to move away from these standards and provide proprietary batteries (Olight) or sealed (some newer Fenix models).It would be good if* We could safely obtain reputable Li-ion batteries from reputable sources. I trust a handful of companies to vet their supply chain so I&#39;m confident of authentic cells like Murata VT6, etc .. but its less than ideal. I don&#39;t think my mom would be able to just find a authentic 18650, and this has to pass the mom test* Easy way to recycle these cells. This needs to expand past home improvement stores, which often seem clueless as to the specifics of what they can accept"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://www.google.com">Is Google.com Down?</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=32393231">
						
							
								<p class="story__comment_first line-clamp">"Comments moved to https://news.ycombinator.com/item?id=32393051."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		

	

	<div class='about'>
		<a href='https://github.com/lopespm/hackernews-daily'>Fork me on GitHub</span>
	</div>

</div>

</body>
</html>