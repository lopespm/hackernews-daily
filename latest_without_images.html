<!doctype html>

<html lang="en">
<head>
	<title>Hacker News Daily</title>
	<meta name="description" content="Lightweight daily best Hacker News posts, with screenshots and top comments. No JavaScript used.">
	<meta name="author" content="Pedro Lopes">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta charset="utf-8">
	<link rel="stylesheet" href="css/styles.css?v=1.0">
	<link href="/favicon.png" rel="icon">
</head>

<body>

<div class="container">

	<div class="navbar">
		<div class="navbar__timespan">
			
				<span class="navbar__timespan_item-current navbar__timespan_item-spacing">Latest</span>
			
			
				<a href='all_without_images.html'>All</a>
			
		</div>
		<div class="navbar__no-images">
			
				<a href='index.html'
				>Enable Previews</a>
			
		</div>
	</div>

	
	<div class="day__date">23 November 2022</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://www.tremendous.com/blog/the-perks-of-a-high-documentation-low-meeting-work-culture">High-documentation, low-meeting work culture</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33707022">
						
							
								<p class="story__comment_first line-clamp">"My current employer was sold to me as a &#34;high documentation&#34; place. What it means in practice is that if you&#39;re trying to do something there are 5 outdated documents describing the decision making process for how the project was run, and no documents about how to actually use the resulting software. Occasionally if you ask how to actually do a task in Slack someone will yell at you that you should have searched for a specific, obscurely named document in Google Drive, Confluence, or Github. We&#39;ve tried a bunch of search tools which successfully surface the million product documents, design documents, PM reports, planning docs, retro docs and standup and oncall notes related to any feature, none of which are up to date."</p>
							
						
							
								<p class="story__comment_others">"I&#39;m convinced that documentation, even for large companies, should just be an Obsidian vault of markdown files maintained via git which is just rendered on the web either using a simple static site generator or using Obsidian Publish. When I brought this up at my last company it got dismissed as being &#39;too technical&#39;.I know git can be tricky but it cannot be that difficult to teach people from non technical departments add, commit and push and then show maybe one person from each department how to solve conflicts. Alternatively, build non technical people a web interface for editing and committing but allow the devs to just use git as standard. Or there&#39;s Obsidian&#39;s built in sync but I don&#39;t know enough about it to know if it scales well in large organisations.What absolutely is definitely not the solution is Confluence. I have not met anyone who has a positive thing to say about it. The only reason it is being so widely used is because it satisfies whoever is in charge of the finances because it comes bundled with Bitbucket and Jira."</p>
							
						
							
								<p class="story__comment_others">"Moving to America from France, one of my biggest surprises was how poor the average engineer (person really, but engineers affect me directly at work) is at summarizing concepts clearly.I learned a little later that &#34;summary&#34; exercises are not a thing taught in school here, which surprised me. In France, &#34;le résumé&#34; is an exercise that they constantly drill into students (particularly technical ones), in which you take a 3 page paper and condense it into 100 words. I really hated doing it back in the day, but as an adult I now am very grateful I did and wished other countries made this more prevalent."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://github.com/terrastruct/d2">D2, a diagram scripting language that turns text to diagrams, is now open source</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33704254">
						
							
								<p class="story__comment_first line-clamp">"Hi HN, I&#39;m Alex, at Terrastruct, where we&#39;ve been making D2. This actually popped up on HN a couple months back, though it wasn&#39;t ready, e.g. not open source yet. It is now!We also put up a site for you to compare D2 with MermaidJS, Graphviz, and PlantUML: https://text-to-diagram.com.Full disclosure, we&#39;re a for-profit company. The open-core part is that we make an alternative layout engine which we sell (Jetbrains model, i.e. your copy is your&#39;s forever if you&#39;ve paid for 12+ months). It&#39;s not packaged with D2, so you won&#39;t see it if you don&#39;t want it. D2 is perfectly usable without it, and integrates with multiple free open source layout engines (e.g. the one that Mermaid uses, &#34;dagre&#34;, is D2&#39;s default). If you want to read more about our plans for D2: https://d2lang.com/tour/future.Hope you can check it out! It&#39;s got an easy install (and uninstall) process."</p>
							
						
							
								<p class="story__comment_others">"I&#39;ve been using PlantUML and Mermaid for my own diagrams.Mermaid is quite basic; it lacks functionalities that for me were necessary; for example, direct connection between attributes of different classes.All in all, PlantUML seems superior to Mermaid, at no cost (both languages are relatively simple to learn).Mermaid is supported by Github, which may be a necessary requirement for some. On the other hand, among the many functionalities, PlantUML&#39;s JSON is unusually good looking out of the box, and if one required the diagram it outputs, it&#39;s a great feature, because it requires no syntax knowledge.Both PlantUML and Mermaid mostly produce (Mermaid more) ugly-looking diagrams (dated, to say the least). In PlantUML, this problem is compounded by the explicit lack of layout, by design.Other warts: both (PlantUML and Mermaid) languages have limited comment support - they are only supported in specific locations of the diagram declarations.D2 could be a very welcome &#34;next gen&#34; diagramming language. However, the devil is in the details - text-to-diagram.com show a very basic functionality, so one must carefully check the requirements.Regarding text-to-diagram.com:- there&#39;s a mistake - PlantUML does support rich text (although &#34;rich&#34; is a fuzzy definition)- class diagrams are an important use case, which is currently missingEDIT: clarification about the comment limitations."</p>
							
						
							
								<p class="story__comment_others">"I recently discovered Pikchr from Sqlite/Fossil [0] if anyone is looking for something in a similar vein, although it has it&#39;s own scripting/layout language rather than using go (a plus IMO, as it&#39;s not tied to a specific ecosystem).It&#39;s fantastic for making diagrams when you want more control over the layout than graphviz or mermaidjs but are looking for a similar type of tool. It&#39;s also clean C so easy to embed, and there&#39;s a WASM build for browser use.It is fairly simple in any general purpose language to output pikchr code - I&#39;ve done this previously for producing autogenerated packet diagrams in documentation.0: https://pikchr.org/home/doc/trunk/homepage.md"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://hacks.mozilla.org/2022/11/improving-firefox-stability-with-this-one-weird-trick/">Improving Firefox stability on Windows by retrying failed memory allocation</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33706117">
						
							
								<p class="story__comment_first line-clamp">"Has Firefox stopped allocating so much RAM that it fills up all my 40GB? Overcommit isn&#39;t always enabled, because I&#39;m not making a 64GB page file just to keep Firefox running for more than a week. (That is how large Windows tried to make it before I disabled the page file.)On my computer, Firefox running out of memory is its own damn fault. Retrying memory allocation won&#39;t fix anything!"</p>
							
						
							
								<p class="story__comment_others">"For a few months now I saw a huge improvement on Linux regarding the memory management of Firefox. Previously I had to run Firefox in a separate cgroup to limit its memory usage, because it could easily deplete my whole RAM. And if I did close most of my tabs it did not release the memory back to the system. Now I never actually get to the limit I&#39;ve set before and also with Auto Tab Discard extension it is well managed. So kudos to the team for such improvements."</p>
							
						
							
								<p class="story__comment_others">"Firefox stability is funny ... I was at Mozilla for 10+ years and used Nightly as my daily driver on my work Mac. I don&#39;t think I got more than one or two dozen crashes in total. A crash was a special occasion and I would walk to someone&#39;s desk to show an explore. It barely every happened. On Nightly. So much love for all the stability work that is happening."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="http://www.bay12games.com/dwarves/features.html">Dwarf Fortress – randomly generated, persistent fantasy world</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33711253">
						
							
								<p class="story__comment_first line-clamp">"I&#39;m always fascinated by Dwarf Fortress whenever I cross paths with it, particularly from a technical architecture point of view. How did they architect the history simulation? How do they efficiently update everything on each tick? What is the game loop like?If anyone has any resources or links to articles, either definitive from the DW developer, or conjecture based on exploration and research, I&#39;d love to learn more about how DF works."</p>
							
						
							
								<p class="story__comment_others">"Not sure why Dwarf Fortress is on the front page, but I will always upvote.If you&#39;re intimidated by ASCII visuals, consider wishlisting the graphics release, scheduled for Dec 6, 2022: https://store.steampowered.com/app/975370/Dwarf_Fortress/"</p>
							
						
							
								<p class="story__comment_others">"Frontend UX developer perspective on DF: The ascii interface is actually fine and mostly a superficial complaint. The real problem is just how hard the many interfaces are to navigate and learn, and how unconventional their designs are. If I could pick one thing for the UI team to focus on: DF needs a “command palette” to help find/learn all of the game’s many functions."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://westling.dev/b/extremely-linear-git">Extremely Linear Git History</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33704297">
						
							
								<p class="story__comment_first line-clamp">"Github-style rebase-only PRs have revealed the best compromise between &#39;preserve history&#39; and &#39;linear history&#39; strategies:All PRs are rebased and merged in a linear history of merge commits that reference the PR#. If you intentionally crafted a logical series of commits, merge them as a series (ideally you&#39;ve tested each commit independently), otherwise squash.If you want more detail about the development of the PR than the merge commit, aka the &#39;real history&#39;, then open up the PR and browse through Updates, which include commits that were force-pushed to the branch and also fast-forward commits that were appended to the branch. You also get discussion context and intermediate build statuses etc. To represent this convention within native git, maybe tag each Update with pr/123/update-N.The funny thing about this design is that it&#39;s actually more similar to the kernel development workflow (emailing crafted patches around until they are accepted) than BOTH of the typical hard-line stances taken by most people with a strong opinion about how to maintain git history (only merge/only rebase)."</p>
							
						
							
								<p class="story__comment_others">"I want the &#39;merge&#39; function completely deprecated. I simply don&#39;t trust it anymore.If there are no conflicts, you might as well rebase or cherry-pick. If there is any kind of conflict, you are making code changes in the merge commit itself to resolve it. Developer end up fixing additional issues in the merge commit instead of actual commits.If you use merge to sync two branches continously, you completely lose track of what changes were done on the branch and which where done on the mainline."</p>
							
						
							
								<p class="story__comment_others">"I don&#39;t know how stupid this is on a scale from 1 to 10. I&#39;ve created a wrapper [1] for git (called &#34;shit&#34;, for &#34;short git&#34;) that converts non-padded revisions to their padded counterpart.Examples:&#34;shit show 14&#34; gets converted to &#34;git show 00000140&#34;&#34;shit log 10..14&#34; translates to &#34;git log 00000100..00000140&#34;[1]: https://github.com/zegl/extremely-linear/blob/main/shit"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://ai.facebook.com/blog/cicero-ai-negotiates-persuades-and-cooperates-with-people/">CICERO: An AI agent that negotiates, persuades, and cooperates with people</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33706750">
						
							
								<p class="story__comment_first line-clamp">"Paper: https://www.science.org/doi/10.1126/science.ade9097Code: https://github.com/facebookresearch/diplomacy_ciceroSite: https://ai.facebook.com/research/cicero/Expert player vs. Cicero AI: https://www.youtube.com/watch?v=u5192bvUS7kRFP: https://ai.facebook.com/research/request-for-proposal/toward...The most interesting anecdote I heard from the team: &#34;during the tournament dozens of human players never even suspected they were playing against a bot even though we played dozens of games online.&#34;"</p>
							
						
							
								<p class="story__comment_others">"I would love to see this kind of thing applied to an RPG.Randomly generate a city full of people. Make a few dozen of them the important NPCs. Give them situations and goals, problems they need to solve and potential ways to solve them. Certain NPC&#39;s goals are opposite others&#39;. Then drop the player into that world and have the &#39;quests&#39; the player is performing be generated based on the NPCs needing their help.Updates wouldn&#39;t be adding new hand-written stories, it would be adding more complexity, more goals, more problems, more things that can be, and the story would generate itself.Done right, this would be incredible."</p>
							
						
							
								<p class="story__comment_others">"https://www.science.org/doi/10.1126/science.ade9097Abstract:
Despite much progress in training AI systems to imitate human language, building agents that use language to communicate intentionally with humans in interactive environments remains a major challenge. We introduce CICERO, the first AI agent to achieve human-level performance in Diplomacy, a strategy game involving both cooperation and competition that emphasizes natural language negotiation and tactical coordination between seven players. CICERO integrates a language model with planning and reinforcement learn- ing algorithms by inferring players’ beliefs and intentions from its conversations and generating dialogue in pursuit of its plans. Across 40 games of an anonymous online Diplomacy league, CICERO achieved more than double the average score of the human players and ranked in the top 10% of participants who played more than one game."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://forums.macrumors.com/threads/icloud-for-windows-corrupting-videos-downloading-other-peoples-photos.2370666/">iCloud for Windows downloading other people&#39;s photos</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33697284">
						
							
								<p class="story__comment_first line-clamp">"In theory this is meant to be one of the advantages of end to end encryption: no more &#34;accidental&#34; leakage of user data between users, leakage in logs, etc (remember Facebook&#39;s logging incident? [0]). as it&#39;s only available on end user devices. And if you look at Apple&#39;s documentation [1], they say that iCloud is end to end encrypted. This is obviously not accurate as Apple keeps decryption keys for themselves. But this issue is even worse: here, the end to end encryption was circumvented in such a bad way that this bug could surface.[0]: https://krebsonsecurity.com/2019/03/facebook-stored-hundreds...[1]: https://support.apple.com/en-us/HT202303"</p>
							
						
							
								<p class="story__comment_others">"This happened to me during a Google Takeout export when I was degoogling in late 2019. I recall going through some photos from the earlier 2010&#39;s and some random pictures of other people were popping up. About a month or so later I received an email from Google letting me know that some of my files may have been accidentally in other people&#39;s exports. Since then, I stopped using apps like Google Photos and cloud storage in general. If I do, my files will be encrypted before I upload them.Here&#39;s the original story: https://9to5google.com/2020/02/03/google-photos-video-strang..."</p>
							
						
							
								<p class="story__comment_others">"This should be a showstopper, critical issue. I’m surprised to see this still be in the wild after being posted on Friday of last week."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://sillycross.github.io/2022/11/22/2022-11-22/">Building the fastest Lua interpreter automatically</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33711583">
						
							
								<p class="story__comment_first line-clamp">"I’ve been working on an early design of a high-performance dynamic binary translator that cannot JIT, and have reached a very similar conclusion as the author. We have an existing threaded interpreter but it’s a mess of hard-to-maintain assembly for two architectures, and we run into funny issues all the time where the two diverge. Plus, being handwritten by people who are not scheduling experts, there is probably some performance left on the table because of our poor choices and the design making it difficult to write complex-but-more-performant code. Nobody wants to write an efficient hash for TLB lookups in a software MMU using GAS macros.The core point I’ve identified is that existing compilers are pretty good at converting high level descriptions of operations into architecture-specific code (at least, better than we are given the amount of instructions we have to implement) but absolutely awful at doing register selection or dealing with open control flow that is important for an interpreter. Writing everything in assembly lets you do these two but you miss out on all the nice processor stuff that LLVM has encoded into Tablegen.Anyways, the current plan is that we’re going to generate LLVM IR for each case and run it through a custom calling convention to take that load off the compiler, similar to what the author did here. There’s a lot more than I’m handwaving over that’s still going to be work, like whether we can automate the process of translating the semantics for each instruction into code, how we plan to pin registers, and how we plan to perform further optimizations on top of what the compiler spits out, but I think this is going to be the new way that people write interpreters. Nobody needs another bespoke macro assembler for every interpreter :)"</p>
							
						
							
								<p class="story__comment_others">"&gt; With the tail-call approach, each bytecode now gets its own function, and the pathological case for the C/C++ compiler is gone. And as shown by the experience of the Google protobuf developers, the tail-call approach can indeed be used to build very good interpreters. But can it push to the limit of hand-written assembly interpreters? Unfortunately, the answer is still no, at least at its current state.&gt; The main blockade to the tail-call approach is the callee-saved registers. Since each bytecode function is still a function, it is required to abide to the calling convention, specifically, every callee-saved register must retain its old value at function exit.This is correct, wasting of callee-saved registers is a shortcoming of the approach I published about protobuf parsing (linked from the first paragraph above).  More recently I have been experimenting with a new calling convention that uses no callee-saved registers to work around this, but the results so far are inconclusive.  The new calling convention would use all registers for arguments, but allocate registers in the opposite order of normal functions, to reduce the chance of overlap.  I have been calling this calling convention &#34;reverse_cc&#34;.I need to spend some time reading this article in more detail, to more fully understand this new work.  I would like to know if a new calling convention in Clang would have the same performance benefits, or if Deegen is able to perform optimizations that go beyond this.  Inline caching seems like a higher-level technique that operates above the level of individual opcode dispatch, and therefore somewhat orthogonal."</p>
							
						
							
								<p class="story__comment_others">"Super interesting.I think using the name LuaJIT Remake steps on the toes of the existing LuaJIT and I would advise using a more original name.Anything distinctive would be better. Lua DeeJIT comes to mind, since the generator is called Deegen."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://twobithistory.org/2019/11/06/doom-bsp.html">The genius of binary space partitioning in Doom (2019)</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33692947">
						
							
								<p class="story__comment_first line-clamp">"Amazingly brilliant work, especially given the CPU capabilities at the time. Carmack&#39;s use of BSP trees inspired my own work on the Crash Bandicoot renderer. I was also really intrigued by Seth Teller&#39;s Ph.D. thesis on Precomputed Visibility Sets though I knew that would never run on home console hardware.None of these techniques is relevant anymore given that all the hardware has Z buffers, obviating the need to explicitly order the polygons during the rendering process. But at the time (mid 90s) it was arguably the key problem 3D game developers needed to solve. (The other was camera control; for Crash Andy Gavin did that.)A key insight is that sorting polygons correctly is inherently O(N^2), not O(N lg N) as most would initially assume. This is because polygon overlap is not a transitive property (A in front of B and B in front of C does NOT imply A in front of C, due to cyclic overlap.) This means you can&#39;t use O(N lg N) sorting, which in turn means sorting 1000 polygons requires a million comparisons -- infeasible for hardware at the time.This is why many games from that era (3DO, PS1, etc) suffer from polygons that flicker back and forth, in front of and behind each other: most games used bucket sorting, which is O(N) but only approximate, and not stable frame to frame.The handful of games that did something more clever to enable correct polygon sorting (Doom, Crash and I&#39;m sure a few others) looked much better as a result.Finally, just to screw with other developers, I generated a giant file of random data to fill up the Crash 1 CD and labeled it &#34;bsptree.dat&#34;. I feel a bit guilty about that given that everyone has to download it when installing the game from the internet, even though it is completely useless to the game."</p>
							
						
							
								<p class="story__comment_others">"BSP (binary space partitioning) was a well known algorithm, not something Carmack picked out of obscurity. It is well covered in every edition of Foley and van Dam&#39;s bible &#34;Computer Graphics&#34;. The arcade game &#34;I, Robot&#34; from Atari (1983) used BSP to render the polygons back to front -- there was no z-buffer.That isn&#39;t to deny that Carmack was brilliant. But him using BSP isn&#39;t some masterstroke of genius in itself."</p>
							
						
							
								<p class="story__comment_others">"I was studying computer graphics at the time. The book we used was &#34;Computer Graphics Principles and Practice&#34; I don&#39;t recall which edition. BSP trees are covered in the book, and like the article says, had been written about more than a decade prior.What Carmack had was the ability to read research papers and translate them into working code. I can do that too, but it does seem to be a less common skill in the software world."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_small-padding-bottom">
			
			<div >
				<div class="story__title">
					<h3><a href="https://wcedmisten.fyi/post/self-hosting-osm/">Self Hosting a Google Maps Alternative with OpenStreetMap</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=33704801">
						
							
								<p class="story__comment_first line-clamp">"How come these map projects still use raster tiles? Are there no open source map projects that render the OSM data to vector data, and renders that vector data on the clients GPU? Maybe raster tiles are better at something I&#39;m missing, but vector maps are easier to style[0], localize, they&#39;re sharper, easier to rotate and zoom smoothly. Maybe it&#39;s harder than I think to render it on all sorts of clients including mobile?When writing this I found out that MapTiler[1] is maintaining MapLibre GL JS[2], a fork of a Mapbox project to do just that. It would be interesting to see the difference between self hosting raster and vector maps and compare pros and cons. You can even render raster tiles from vector tiles on the server if the client needs it[3].[0] https://openmaptiles.org/docs/style/mapbox-gl-style-spec/[1] https://www.maptiler.com/open-source/[2] https://github.com/MapLibre/maplibre-gl-js[3] https://openmaptiles.org/docs/host/tileserver-gl/"</p>
							
						
							
								<p class="story__comment_others">"Vector map of the whole Earth in PMTiles format is only ~65GB[1] and doesn&#39;t need any server or database - it&#39;s just a static file which you can host wherever you want.bdon (author of PMTiles) already commented on this thread. I recommend taking a look at https://protomaps.com/docs - compared to this, raster tile servers sound like ancient technology.[1]: https://app.protomaps.com/store/planet-z14"</p>
							
						
							
								<p class="story__comment_others">"Thank you! It&#39;s on my todo-list to set up such a server and your work will really help with it.Here is another excellent write-up from Stefan Erhardt who is the founder of OpenTopoMap [0][1] which gives step-by-step instructions [2] on how to set up a tile server with custom tile rendering, also based on OSM&#39;s data.Also worth mentioning is GeoServer [3][0] https://opentopomap.org/[1] https://github.com/der-stefan/OpenTopoMap[2] https://github.com/der-stefan/OpenTopoMap/blob/master/mapnik...[3] https://geoserver.org/"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		

	

	<div class='about'>
		<a href='https://github.com/lopespm/hackernews-daily'>Fork me on GitHub</span>
	</div>

</div>

</body>
</html>