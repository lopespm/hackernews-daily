<!doctype html>

<html lang="en">
<head>
	<title>Hacker News Daily</title>
	<meta name="description" content="Lightweight daily best Hacker News posts, with screenshots and top comments. No JavaScript used.">
	<meta name="author" content="Pedro Lopes">
	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<meta charset="utf-8">
	<link rel="stylesheet" href="css/styles.css?v=1.0">
	<link href="/favicon.png" rel="icon">
</head>

<body>

<div class="container">

	<div class="navbar">
		<div class="navbar__timespan">
			
				<span class="navbar__timespan_item-current navbar__timespan_item-spacing">Latest</span>
			
			
				<a href='all_with_images.html'>All</a>
			
		</div>
		<div class="navbar__no-images">
			
				<a href='latest_without_images.html'
				>Disable Previews</a>
			
		</div>
	</div>

	
	<div class="day__date">22 February 2022</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://twitter.com/xenadu02/status/1495693475584557056">
						<picture>
							<source srcset="default_30419618.webp" type="image/webp">
							<source srcset="default_30419618.png" type="image/png">
							<img src="default_30419618.png" alt="Preview of 'I tested four NVMe SSDs from four vendors – half lose FLUSH’d data on power loss'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://twitter.com/xenadu02/status/1495693475584557056">I tested four NVMe SSDs from four vendors – half lose FLUSH’d data on power loss</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30419618">
						
							
								<p class="story__comment_first line-clamp">"I always liked the embedded system model where you get flash hardware that has two operations -- erase block and write block.  GC, RAID, error correction, etc. are then handled at the application level.  It was never clear to me that the current tradeoff with consumer-grade SSDs was right.  On the one hand, things like the error correction, redundancy, and garbage collection don&#39;t require the attention from CPU (and more importantly, doesn&#39;t tie up any bus).  On the other hand, the user has no control over what the software on the SSD&#39;s chip does.  Clearly vendors and users are at odds with each other here; vendors want the best benchmarks (so you can sort by speed descending and pick the first one), but users want their files to exist after their power goes out.It would be nice if we could just buy dumb flash and let the application do whatever it wants (I guess that application would be your filesystem; but it could also be direct access for specialized use cases like databases).   If you want maximum speed, adjust your settings for that.  If you want maximum write durability, adjust your settings for that.  People are always looking for that one size fits all use case, but it&#39;s hard here.  Some people may be running cloud providers and already have software to store that block on 3 different continents.  Some people may be an embedded system with a fixed disk image that changes once a year, with some temporary storage for logs.  There probably isn&#39;t a single setting that gets optimal use out of the flash memory for both use cases.  The cloud provider doesn&#39;t care if a block, flash chip, drive, server rack, availability zone, or continent goes away.  The embedded system may be happy to lose logs in exchange for having enough writes left to install the next security update.It&#39;s all a mess, but the constraints have changed since we made the mess.  You used to be happy to get 1/6th of a PCI Express lane for all your storage.  Now processors directly expose 128 PCIe lanes and have a multitude of underused efficiency cores waiting to be used.  Maybe we could do all the &#34;smart&#34; stuff in the OS and application code, and just attach commodity dumb flash chips to our computer."</p>
							
						
							
								<p class="story__comment_others">"I&#39;ve actually run into some data loss running simple stuff like pgbench on Hetzner due to this -- I ended up just turning off write-back caching at the device level for all the machines in my cluster:https://vadosware.io/post/everything-ive-seen-on-optimizing-...Granted I was doing something highly questionable (running postgres with fsync off on ZFS) It was very painful to get to the actual issue, but I&#39;m glad I found out.I&#39;ve always wondered if it was worth pursuing to start a simple data product with tests like these on various cloud providers to know where these corners are and what you&#39;re really getting for the money (or lack thereof).[EDIT] To save people some time (that post is long), the command to set the feature is the following:    nvme set-feature -f 6 -v 0 /dev/nvme0n1

The docs for `nvme` (nvme-cli package, if you&#39;re Ubuntu based) can be pieced together across some man pages:https://man.archlinux.org/man/nvme.1https://man.archlinux.org/man/nvme-set-feature.1.enIt&#39;s a bit hard to find all the NVMe features but 6 is the one for controlling write-back caching.https://unix.stackexchange.com/questions/472211/list-feature..."</p>
							
						
							
								<p class="story__comment_others">"I think this is something LTT could handle with their new test lab. They already said they want to set new standards when it comes to hardware testing, so if they can hold up to what they promised and hire enough experts this should be a trivial thing to add to a test Parcours for disk drives."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://memex.marginalia.nu/log/48-i-have-no-capslock.gmi">
						<picture>
							<source srcset="default_30421399.webp" type="image/webp">
							<source srcset="default_30421399.png" type="image/png">
							<img src="default_30421399.png" alt="Preview of 'I have no capslock and I must scream'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://memex.marginalia.nu/log/48-i-have-no-capslock.gmi">I have no capslock and I must scream</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30421399">
						
							
								<p class="story__comment_first line-clamp">"Very similar to A Plan for the Improvement of English Spelling by M. J. Shields (frequently misattributed to Mark Twain):&#34;For example, in Year 1 that useless letter &#34;c&#34; would be dropped to be replased either by &#34;k&#34; or &#34;s&#34;, and likewise &#34;x&#34; would no longer be part of the alphabet. The only kase in which &#34;c&#34; would be retained would be the &#34;ch&#34; formation, which will be dealt with later. Year 2 might reform &#34;w&#34; spelling, so that &#34;which&#34; and &#34;one&#34; would take the same konsonant, wile Year 3 might well abolish &#34;y&#34; replasing it with &#34;i&#34; and Iear 4 might fiks the &#34;g/j&#34; anomali wonse and for all.Jenerally, then, the improvement would kontinue iear bai iear with Iear 5 doing awai with useless double konsonants, and Iears 6-12 or so modifaiing vowlz and the rimeining voist and unvoist konsonants. Bai Iear 15 or sou, it wud fainali bi posibl tu meik ius ov thi ridandant letez &#34;c&#34;, &#34;y&#34; and &#34;x&#34; -- bai now jast a memori in the maindz ov ould doderez -- tu riplais &#34;ch&#34;, &#34;sh&#34;, and &#34;th&#34; rispektivli.Fainali, xen, aafte sam 20 iers ov orxogrefkl riform, wi wud hev a lojikl, kohirnt speling in ius xrewawt xe Ingliy-spiking werld.&#34;"</p>
							
						
							
								<p class="story__comment_others">"This is cute but it refuses to actually think about the problem of keyboard layout design. Take the reductio the other way and you end up adding keys to create a keyboard with a key for “the” and one for “and”, “or”, “but”, “of”... The author is just saying they want the QWERTY keyboard exactly as it is without actually thinking how this layout got there in the first place.The Caps Lock key makes no sense in the context of a computer keyboard. Back in the days of typewriters when everything was a single monospaced font, typing in all caps was the only way to make something bold (there weren’t italics, bold, font sizes or different fonts). Having a convenient way to hold down the shift key was nice in this context. In the context of a computer keyboard that has multiple fonts, sizes and weights, it is a dumb key. Larry Tesler’s dictum “no modes” is immediately applicable. Steve Jobs tried to get rid of the caps lock key twice (once at Apple and once at Next). Google’s pixel books have replaced it with a search shortcut, which is not that useful but much better than having a key whose primary function is to mess up password entry and shout online without any extra effort for shouting. On a Mac keyboard there are a few common substitutions for caps lock that you can use. Any of these substitutions are preferable (I have it as Option for tab navigation but any of the other main hot keys make a better use of keyboard real estate)."</p>
							
						
							
								<p class="story__comment_others">"The title is a reference to this story by Harlan Ellison, which won a Hugo award in 1968:[NSFW - contains graphic descriptions of torture and other severe violence]https://wjccschools.org/wp-content/uploads/sites/2/2016/01/I..."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://forums.swift.org/t/core-team-to-form-language-workgroup/55455/6">
						<picture>
							<source srcset="default_30416070.webp" type="image/webp">
							<source srcset="default_30416070.png" type="image/png">
							<img src="default_30416070.png" alt="Preview of 'Chris Lattner left Swift core team'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://forums.swift.org/t/core-team-to-form-language-workgroup/55455/6">Chris Lattner left Swift core team</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30416070">
						
							
								<p class="story__comment_first line-clamp">"&gt; It is obvious that Swift has outgrown my influence, and some of the design premises I care about (e.g. &#34;simple things that compose&#34;)As someone who was heavily invested in Swift, and an active member of the community from around 2015-2019, I&#39;m a bit sad to see the direction the language is taking.From the time I started experimenting with Swift, I absolutely loved the philosophy of the language.  It seemed to really prioritize having a set of well-factored systems, each with their own very rationally designed interfaces, which could be composed to do really powerful things.  It was an incredibly expressive language which allowed for writing code with an incredible level of clarity - when writing Swift code I always felt I was writing at the level of the problem domain, not writing syntax.  At the same time it offered really nice features for ensuring safety and correctness, like ADT&#39;s and best-in-class nullability syntax.It was a language which sometimes seemed to move at a glacial pace, but the implicit tradeoff was that when a feature landed, it was for the most part very well thought out, and would add to the language with minimal negative impact.A few years ago that seemed to start to change.  From my perspective, some of the features added to the language to support SwiftUI - specifically property wrappers and function builders - very much felt rushed and forced into the language based on external deadlines.  And imo they have a largely negative impact on the language: it used to be the case that you could look at a piece of Swift code and roughly understand how it would compile to assembly pretty easily, but with these new features there&#39;s a ton of compiler magic going on behind the scenes."</p>
							
						
							
								<p class="story__comment_others">"I clicked on this thread because I knew exactly what I wanted to comment about, and was surprised to see that Chris mentioned exactly it in his message:&gt;After several discussions generating more heat than light, when my formal proposal review comments and concerns were ignored by the unilateral accepts, and the general challenges with transparency working with core team, I decided that my effort was triggering the same friction with the same people, and thus I was just wasting my time.I stopped paying attention to Swift for this exact reason. I have actually submitted and implemented a feature in Swift and I think it was one of my most frustrating experiences with open-source projects. It seems that almost every thread in this forum devolves into people fighting over the most irrelevant details, and my proposal specifically took months to be submitted into review because a couple of users simply refused to back down from how they personally wanted it to work, ignoring the actual problem the feature aimed to solve. After a long time deflecting the comments, the feature was accepted the way I originally intended and I never entered the forum again.Example aside, it doesn&#39;t take a proposal to see that almost every thread in the forum looks like this. Open sourcing Swift has benefits, but I think when it comes to the actual progress of the project, this particular democratic process was a mistake."</p>
							
						
							
								<p class="story__comment_others">"Key takeaway for me was the note that it “definitely isn’t a community designed language”. This is telling, I’ve watched a lot of neat languages over the years and absolutely none of the ones without community involvement have grown beyond the sphere of influence of their primary companies.I like swift enough I’m learning it to build my own personal tech nerd ideal podcast client because I own apple devices and want an app that works between macOS, iOS, iPadOS, tvOS,and watchOS. but I doubt I’ll ever use it for anything beyond this one personally motivated project. Even if i release it as an app on the store for download or purchase I don’t know if I will ever be motivated enough to build anything else using it. Because the scope is too narrow. Business work is converging on open stacks like react, and angular, and the dark horse of C# with its latest release supporting WASM web components backed by GRPC-web and a C# function driven stack from front to back, even without SQL Server costs this is a compelling ecosystem backed by PostgreSQL and other completely open source tools.But Swift remains Apple’s language for apple stuff and… while a profitable niche, it’s still a niche.Edit: typo fix."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://web3isgoinggreat.com/?id=2022-02-21-0">
						<picture>
							<source srcset="default_30420990.webp" type="image/webp">
							<source srcset="default_30420990.png" type="image/png">
							<img src="default_30420990.png" alt="Preview of 'Coinbase CEO tweets how they came up with Super Bowl ad, lied about it'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://web3isgoinggreat.com/?id=2022-02-21-0">Coinbase CEO tweets how they came up with Super Bowl ad, lied about it</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30420990">
						
							
								<p class="story__comment_first line-clamp">"Coinbase CEO&#39;s excuse is that he sees Martin Agency as a &#34;creative firm&#34; not a &#34;traditional ad agency&#34; and he felt they &#34;were all one team&#34;. Although it should be noted that last Tweet was posted hours after the original set of Tweets.https://twitter.com/brian_armstrong/status/14958203518796595..."</p>
							
						
							
								<p class="story__comment_others">"Plot twist: this drama is fabricated and is part of a meta-advertising package offered by The Martin Agency."</p>
							
						
							
								<p class="story__comment_others">"Tangent, but I thought it was a funny commentary: I was watching the olympics with my kid (&lt;12yo) and the Coinbase commercial came on (Didn&#39;t see it during the superbowl, but I assume they were the same?). And after the commercial ended my kid said, &#34;was that... some kind of app for gambling or something?&#34;Yes. Something like that. :)"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://news.ycombinator.com/item?id=30413228">
						<picture>
							<source srcset="default_30413228.webp" type="image/webp">
							<source srcset="default_30413228.png" type="image/png">
							<img src="default_30413228.png" alt="Preview of 'Tell HN: Airbnb just stole me 5 minutes of my time adding dices'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://news.ycombinator.com/item?id=30413228">Tell HN: Airbnb just stole me 5 minutes of my time adding dices</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30413228">
						
							
								<p class="story__comment_first line-clamp">"I see this as high-IQ software developers building systems to shut out non-high-IQ people from society. Managers look at these CAPTCHAs and think &#34;oh I could solve these no problem, let&#39;s use them&#34;. In fact, they can only be solved by unusually smart people or by ML bots. Arkose Labs (the maker of this particular captcha) explicitly advertises that their methods can keep out &#34;low-skilled workers&#34; on &#34;human fraud farms&#34;. They keep out everyone else too if they&#39;re not that good at mental rotation and mental arithmetic or logic -- this dice puzzle and the mouse labyrinth puzzle are pretty much prototypical IQ test problems."</p>
							
						
							
								<p class="story__comment_others">"It&#39;s Arkose Labs (also used by Roblox, GitHub, Dropbox, Twitch, and more). There&#39;s some more links here: https://github.com/dessant/buster/issues/178 (Buster is a browser extension for automated captcha solving). You can subscribe here https://github.com/dessant/buster/issues/320Their audio captcha (no longer available?) involved listening to 3 MIDI tunes and picking &#34;the sad one&#34;."</p>
							
						
							
								<p class="story__comment_others">"Airbnb has been very human hostile since the beginning.The first time I had to create an account, they required that I connect with a google account with access to all my contacts. Then ask me to make a video of myself.I didn&#39;t create the account and booked an hotel.Now they are less aggressive with their new procedures, but still, you can see that the people behind it see technical solutions way before they perceive the human impact.My grand-father was like that. A brilliant engineer from the most elite school of his generation in France. He once told me very seriously a solution for making more accommodations for the poorest people would be to remove individual bathrooms, and create common ones for the whole building instead.Airbnb tech teams remind me of him."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://groups.google.com/g/vim_announce/c/MJBKVd-xrEE/m/joVNaDgAAgAJ">
						<picture>
							<source srcset="default_30416558.webp" type="image/webp">
							<source srcset="default_30416558.png" type="image/png">
							<img src="default_30416558.png" alt="Preview of 'Vim 9 will be dedicated to Sven Guckes'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://groups.google.com/g/vim_announce/c/MJBKVd-xrEE/m/joVNaDgAAgAJ">Vim 9 will be dedicated to Sven Guckes</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30416558">
						
							
								<p class="story__comment_first line-clamp">"  &gt; Our friend Sven Guckes died in Berlin on February 20, 2022.
  &gt; He was diagnosed with a brain tumor in December 2021.

Sheesh so fast... scary. RIP."</p>
							
						
							
								<p class="story__comment_others">"I’m surprised about Sneak’s comment being flagged on here.It’s okay to express your opinion about the person being discussed and add more information to it in general.If VIM is being dedicated to an alleged sexual harasser, I as an interested person is happy to know about this."</p>
							
						
							
								<p class="story__comment_others">"I&#39;ve used Vim nearly every day for the last 20 years. Thank you for FOSS. RIP."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1938081">
						<picture>
							<source srcset="default_30417811.webp" type="image/webp">
							<source srcset="default_30417811.png" type="image/png">
							<img src="default_30417811.png" alt="Preview of 'What are the most important statistical ideas of the past 50 years?'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://www.tandfonline.com/doi/full/10.1080/01621459.2021.1938081">What are the most important statistical ideas of the past 50 years?</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30417811">
						
							
								<p class="story__comment_first line-clamp">"Validation on holdout sets.When I was a student in the 1990s, I was taught about hypothesis testing (and all the hassle of p-fishing etc.), and about Bayesian inference (which is lovely, until you have to invent priors over the model space -- e.g. a prior over neural network architectures). These are both systems that tie themselves in epistemological knots when trying to answer the simple question &#34;What model shall I use?&#34;Holdout set validation is such a clean simple idea, and so easy to use (as long as you have big data), and it does away with all the frequentist and Bayesian tangle, which is why it&#39;s so widespread in ML nowadays.It also aligns statistical inference with Popper&#39;s idea of scientific falsifiability -- scientists test their models against a new experimental data, data scientists can test their model against qualitatively different holdout sets. (Just make sure you don&#39;t get your holdout set by shuffling, since that&#39;s not what Popper would call a &#34;genuine risky validation&#34;.)The article mentions Breiman&#39;s &#34;alternative view of the foundations of statistics based on prediction rather than modeling&#34;. Breiman does make a big deal of evaluation on holdout sets; but his &#34;prediction&#34; idea isn&#39;t general enough, since it doesn&#39;t accommodate generative modelling (e.g. GPT, GANs). I think it&#39;s better to frame ML in terms of &#34;evaluating model fit on a holdout set&#34;, since that accommodates both predictive and generative modelling."</p>
							
						
							
								<p class="story__comment_others">"Off-the-cuff, i.e. without digging deeply into a set of history of statistics books:Tied 1st place:• Markov chain Monte Carlo (MCMC) and the Metropolis–Hastings algorithm• Hidden Markov Models and the Viterbi algorithm for most probable sequence in linear time• Vapnik–Chervonenkis theory of statistical learning (Vladimir Naumovich Vapnik &amp; Alexey Chervonenkis) and SVMs4th place:• Edwin Jaynes: maximum entropy for constructing priors (borderline: 1957)Honorable mentions:• Breiman et al.&#39;s CART (Classification and Regression Trees) algorithm (and Quinlan&#39;s C5.0 extension)• Box–Jenkins method (autoregressive moving average (ARMA) / autoregressive integrated moving average (ARIMA) to find the best fit of a time-series model to past values of a time series)(The beginning of the 20th century was much more fertile in comparison - Kolmogorov, Fisher, Gosset, Aitken, Cox, de Finetti, Kullback, the Pearsons, Spearman etc.)"</p>
							
						
							
								<p class="story__comment_others">"This is a side issue, but I wonder what changes could be made to the teaching of statistics, most importantly &#34;stats for scientists&#34; taught in college and even high school. What occurs to me right off the bat is that I learned stats by the use of formulas to boil data sets down to answers. For example, null hypothesis significance testing and the dreaded p-value. We had to do it this way, as widespread availability of computers was still on the horizon.Today, computation is easy and cheap. I wonder if we could learn stats in a different way, perhaps starting by just playing with data, and simulated random numbers, graphing, and so forth. Can something like null hypothesis testing be taught primarily through bootstrapping, with the formulas introduced as an aside?Yes I know that statistics is a formal branch of math, with theorems and proofs. I took that class. But the students who take &#34;stats for scientists&#34; don&#39;t ever see that side of it. Understanding the formulas without seeing the proofs is like trying to learn freshman physics without calculus."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://revelry.co/insights/development/nix-time/">
						<picture>
							<source srcset="default_30384121.webp" type="image/webp">
							<source srcset="default_30384121.png" type="image/png">
							<img src="default_30384121.png" alt="Preview of 'Nix: An idea whose time has come'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://revelry.co/insights/development/nix-time/">Nix: An idea whose time has come</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30384121">
						
							
								<p class="story__comment_first line-clamp">"I love the idea of nix but the inconsistency and developer experience is terrible.   I want to suggest people use it but there is too many rough edges currently.For example, if you want to install a package the old way, you&#39;ll install it including the channel:    nix-env -iA nixpkgs.ripgrep


but then if you want to remove one, you don&#39;t reference the channel:    nix-env -e ripgrep

You have a similar issue if you want to use the new `nix` command.  To install a package you&#39;ll do:    nix profile install nixpkgs#ripgrep


but running:    nix profile remove nixpkgs#ripgrep


will do nothing.  It won&#39;t say &#34;I didn&#39;t remove the package&#34; or &#34;package not found&#34;.  It just returns silently.    The only way to remove it is to point to the number from `nix profile history` or the actual path.It is unbearably slow:    &gt; time nix-env -qaP ripgrep
    nixpkgs.ripgrep  ripgrep-13.0.0

    11.17s user 2.70s system 73% cpu 18.970 total


Overall I love the idea but it has a long way to go in developer experience and quality before it is ready for any mainstream adoption."</p>
							
						
							
								<p class="story__comment_others">"  &gt; Nix often scares newcomers and experienced devs alike, because it proposes a fairly radical overhaul to how we think about package management and how we run software in general.

I am not sure this is the main put-off of nix.Ideologically, I love nix. The syntax/language itself is a massive barrier IMO.I use Nix for personal projects, but I prefer the experience of Devcontainers. They&#39;re easier to understand and debug (for me).I&#39;m watching eagerly the work being done by the ostree/rpm-ostree folks who are also trying to solve for a similar problem. Hoping to see something like &#34;Nix but with YAML/JSON&#34; come out of that.https://ostree.readthedocs.io/en/stable/manual/related-proje..."</p>
							
						
							
								<p class="story__comment_others">"I have been running NixOS and uxing Nix for almost everything since I switched to it, and my experience has been great so far. It is one versatile solution to a lot of applications:1. I run NixOs on on laptop and workstation, for work and for personal use. Any change to the configuration can be immediately transfered to other machines. And give me a new machine, I can quickly bring it up with the configuration that I am always using.
2. I run NixOS on my home server and machine learning cluster. Deploy experiment and service on them is as simple as updating the git-managed configurations. Meanwhile, if I want to use more power to run an experiment, NixOps can quickly bring up a set of machines on AWS with the configuration identical to my local experiment. You do not need to worry about setting up CUDA/pytorch and other dependencies every.
3. In my start-up, it definitely took more time to train the developers to learn Nix, but once they get familiar, everyone becomes a good DevOps engineer, which solves development environemnt (that invloves C++/Python), CI/CD and release really well."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://probablydance.com/2022/02/19/reasons-why-babies-cry-in-the-first-three-months-how-to-tell-them-apart-and-what-to-do/">
						<picture>
							<source srcset="default_30401882.webp" type="image/webp">
							<source srcset="default_30401882.png" type="image/png">
							<img src="default_30401882.png" alt="Preview of 'Why babies cry in the first three months, how to tell them apart, and what to do'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://probablydance.com/2022/02/19/reasons-why-babies-cry-in-the-first-three-months-how-to-tell-them-apart-and-what-to-do/">Why babies cry in the first three months, how to tell them apart, and what to do</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30401882">
						
							
								<p class="story__comment_first line-clamp">"Of kids I&#39;ve always thought &#34;maybe one day&#34;.  I can see how it&#39;d be a tough, but extremely rewarding and meaningful endeavor.But reading this article made me think for the first time &#34;actually, I think I don&#39;t want kids.&#34;So many &#34;mental CPU cycles&#34; spent learning about pregnancy, babies, why they cry, how to care for them.  It just doesn&#39;t appeal to me at all - I think it&#39;d resent it taking me away from spending time on the topics that legitimately interest me -   stuff like space, technology, fiction, stocks, politics, philosophy, hobbies.  (I realize how much this comes off as a young white tech nerd... But that&#39;s exactly what I am!)And all this just of the knowledge gathering.  We haven&#39;t even touched on the truly hard part - executing it!I guess this article made raising a kid real in a way that none other have before.  Took the high ideal of &#34;raising a family&#34; and shined light on all the tough, hard realities.Of course this is all from my current perspective.  I&#39;m sure it all totally changes in ways I just can&#39;t conceive when it&#39;s your own kid.Open to any insights from others who may have been here before!"</p>
							
						
							
								<p class="story__comment_others">"Great if it works for you, but for those who are dealing with babies, I wouldn&#39;t beat myself up if this advice doesn&#39;t apply. The parenting advice world is chock full of people who found something that worked for them and who then made the unwarranted conclusion that it is universal truth. For example, their techniques that &#34;always work&#34; definitely do not always work. Maybe they always worked for their particular babies, but I have been in situations with my kids where neither shushing and patting nor holding and walking worked to stop crying.My general feeling is that you can drive yourself nuts trying to figure out why your baby is crying, and, as the blog author mentioned in his conclusion, you may still be unable to figure it out. IMO this is a great time of one&#39;s life to discard the illusion of control."</p>
							
						
							
								<p class="story__comment_others">"Newly minted dad of twins and uncle for 5 others.Infant phaseThe work is intense when they are young since they can’t do much on their own and need help very often. But this doesn’t last for too long. Most parents exaggerate this phase since it is very intense from their otherwise happy days without kids. I had enough nephews and nieces around that I helped with so my kids are not the first time I am doing something this intense.Toddler phaseThey are very manageable because of their size. Not those helpless poor little things any more. But they need to be entertained. Having others kids help a lot here. One more reason to have more than one kids. Only kids can match kids energy level.Beyond infantsThis is when things get interesting they start engaging with you a lot with words and actions.Most of the problems with millennials for fear of having kids got to do with not having much experience before having their own. So they get overwhelmed, this is very specific to societies with lack of communities (western urban societies).Once your friends have kids they are out of your circle since they cannot come out and do as much as they used to do.With medical advancements and tools available to raise a child it is lot easier to raise kids than before. Over focusing on parenthood is also another issue. This is product of abundance of time and money. My mom of 3 children didn’t have tools and time to engage with us like our generation do. She did exceptionally well without over indulging in the name of parenthood.Note: I am leaning game development and reading books while having full time job and having twins as my first children on my own at 40.It’s totally doable. Try being around your friends with kids, that’s helpful for them as well as you.Most rewarding thing and easily attainable for most of us is to raise children never forget the entertainment and stress buster aspect of having kids as well.Once a wise women from the east said to us raised in the west: If you can have pets I don’t seem to understand your issues having kids. Kids are Pets+++"</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		
		<div class="story story_large-padding-bottom">
			
				<div class="story__thumbnail">
					<a href="https://vaghetti.dev/posts/times-are-great/">
						<picture>
							<source srcset="default_30410856.webp" type="image/webp">
							<source srcset="default_30410856.png" type="image/png">
							<img src="default_30410856.png" alt="Preview of 'Times are great for programmers now. How does it end?'">
						</picture>
					</a>
				</div>
			
			<div class="story__title-and-comments_with-images">
				<div class="story__title">
					<h3><a href="https://vaghetti.dev/posts/times-are-great/">Times are great for programmers now. How does it end?</a></h3>
				</div>
				<div class="story__comments">
					<div class="story__comment">
						<a href="https://news.ycombinator.com/item?id=30410856">
						
							
								<p class="story__comment_first line-clamp">"I feel like we have so much leverage and don&#39;t use it at all.We&#39;re still attending stand-ups every day with non programmers telling us when we can and cannot refactor. It&#39;s nuts to me that a skilled profession - that not many can do - lets themselves get micro-managed like this.If anyone has read Developer Hegemony, I&#39;m fully on board with that general premise - we start operating like lawyers with partnerships, and turn bosses into customers. Though that does require us to think of ourselves as professionals not nerds who are too smart for business."</p>
							
						
							
								<p class="story__comment_others">"Programmers are increasingly needed for *everything*.I mean, we&#39;ve entered an age, where a farmer can&#39;t milk their cows, if the software of the milking robot has a hitch - can&#39;t plow their fields, when the gps-software that drives the tractor isn&#39;t working.Apart from that, programming is becoming every other job - as far as domain knowledge is concerned.I&#39;ve personally experienced (multiple times!) professional accounting companies complaining about not being able to just modify official invoices (totally illegal) but having to cancel and re-issue them with a new invoice number (how it MUST be done).
-&gt; It&#39;s now the responsibility of the programmers to understand how accounting works. Professional accountants just click a button and expect the software to &#34;do the right thing&#34;.
-&gt; As in this case, the professional accountant no longer adds much value, they&#39;ll probably be entirely replaced by software at some point.A more relatable example might be Taxis drivers. It might take years still, but at some point, all Taxis will be self-driving vehicles, created by robots in a fully automated factory. Programmers will be needed for the driving software and the factory software. You might still need some mechanics to repair the factory robots - until when that job is done by robots as well (that have to be programmed).It currently seems more likely to me, that we are headed towards a future, where programming is the *only* job - and everything else is done by software."</p>
							
						
							
								<p class="story__comment_others">"I think it ends with everyone becoming a developer.Making machines do things will never end. However, the tools for making machines do things is evolving very quickly.The general art of being a developer will continue to get specialized and at some point specialists at any field would be expected to be able to program their machines.Very few people are learning how to run their servers and much more are moving into AWS type of infrastructure and “cloud literacy” has become a thing.I would expect layers of abstraction to continue to build up and programming to become something like using spreadsheets to do your actual task.Eventually, “true programming” will scale back to building these tools. It would be rather niche, very high skill serious engineering - an elite, hard to get in profession that continues to fetch high salaries. They probably will have some kind of association similar to the lawyers/doctors, the code they write will no longer tolerate bugs as a fact of life but they will be responsible as any other licensed professionals. Skipping unit test will land you in jail or very high fine due to malpractice if something goes wrong."</p>
							
						
						</a>
					</div>
				</div>
			</div>
		</div>
		

	

	<div class='about'>
		<a href='https://github.com/lopespm/hackernews-daily'>Fork me on GitHub</span>
	</div>

</div>

</body>
</html>